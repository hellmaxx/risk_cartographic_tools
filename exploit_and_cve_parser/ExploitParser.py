from urllib import response
import requests
from bs4 import BeautifulSoup
import datetime
import time
from neo4j import GraphDatabase

DOMAIN = 'https://www.exploit-db.com/'
URL = 'https://www.exploit-db.com/exploits/'
codeURL = 'https://www.exploit-db.com/raw/'
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.3',
}

neo4j_driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "1234"))
session = neo4j_driver.session()

def getPage(exploit_number):
    response_page = requests.get(URL + str(exploit_number), headers=HEADERS)
    return BeautifulSoup(response_page.content, 'html.parser')


def getName(soup):
    items = soup.find("h1", class_='card-title text-secondary text-center')
    return items.text.strip()


def getEdID(soup):
    items = soup.find("h6", class_='stats-title')
    return items.text.strip()


def getCVE(soup):
    items = soup.findAll("h6", class_='stats-title')
    text = []

    for item in items:
        text.append(item.getText)

    t = text[1].__str__().split()
    if len(t) > 8:
        return 'CVE-' + t[9]
    else:
        return 'No CVE'


def getVerified(soup):
    items = soup.findAll("i", class_='mdi mdi-24px mdi-check')
    text = []
    for item in items:
        text.append(item.getText)

    if 'style=\"color: #96b365\"' in text.__str__():
        return 'Verified'
    else:
        return 'No verified'


def getAuthor(soup):
    items = soup.findAll("h6", class_='stats-title')

    text = []
    for item in items:
        text.append(item.getText)

    t = text[2].__str__().split()
    if len(t) >= 12:
        return t[8] + ' ' + t[9]
    else:
        return t[8]


def getType(soup):
    items = soup.findAll("h6", class_='stats-title')
    text = []

    for item in items:
        text.append(item.getText)

    t = text[3].__str__().split()
    if len(t) >= 11:
        return t[8]
    else:
        return t[7]


def getLinks(exploit_number):
    return URL + str(exploit_number)


def getCodeLink(exploit_number):
    return codeURL + str(exploit_number)


def getDomain():
    domain = DOMAIN
    return domain


def getPlatform(soup):
    items = soup.findAll("h6", class_='stats-title')
    text = []

    for item in items:
        text.append(item.getText)

    t = text[4].__str__().split()
    if len(t) >= 11:
        return t[8]
    else:
        return t[7]


def getDate(soup):
    items = soup.findAll("h6", class_='stats-title')
    text = []
    for item in items:
        text.append(item.getText)

    t = text[5].__str__().split()
    if len(t) >= 11:
        return t[8]
    else:
        return t[6]


def getDateSeen():
    date = datetime.date.today()
    return ''.join(str(date.year) + '-' + str(date.month) + '-' + str(date.day))


def pageFound(soup):
    page = soup.findAll('h1', class_='card-title')
    if str(page).__eq__("[]") or str(page).__contains__("404") :
        return False
    else :
        return True


def main():
    exception_count = 0
    exploit_number =  51009

    while exception_count < 47834:
        soup = getPage(exploit_number)

        if pageFound(soup) is False:
            print('\033[31m {}'.format('404. Exploit with id=' + str(exploit_number) + ' is not exists'))
            exploit_number -= 1
            exception_count += 1
        else:
            if exploit_number % 10 == 0:
                time.sleep(10)

            cve = getCVE(soup)
            edbid = getEdID(soup)
            name = getName(soup).replace("'", " ").replace("\"", "\'")
            verifide= getVerified(soup)
            author = getAuthor(soup).replace("'", "\'").replace("\"", "\'")
            datePublishing= getDate(soup)
            dateNow = getDateSeen()
            typeExploit = getType(soup)
            platform = getPlatform(soup).replace("'", "\'").replace("\"", "\'")
            linkExploit = getLinks(exploit_number)
            linkCode = getCodeLink(exploit_number)
            domain = getDomain()
            
            # Запрос CVE
            if (cve != 'None'):
                query = "MERGE (cve:CVE {id: '" + cve + "'}) \n"
                result = session.run(query)

            # Запрос Exploit
            query = "MERGE (exploit:EXPLOIT {id: '" + edbid + "'}) SET exploit.name='" + name + "',exploit.date='" + datePublishing + "',exploit.verifide='" + verifide + "',exploit.author='" + author + "', exploit.dateSeen='" + dateNow + "' \n" 
            query = query + "MERGE (cve:CVE {id: '" + cve + "'}) \n"
            query = query + "MERGE (exploit)-[r:EXPLOITtoCVE]->(cve)"
            result = session.run(query)

            # Запрос Platform
            query = "MERGE (exploit:EXPLOIT {id: '" + edbid + "'})"
            query = query + "MERGE (platform:PLATFORM {id: '" + platform + "'}) \n"
            query = query + "MERGE (exploit)-[r:EXPLOITtoPLATFORM]->(platform)"
            result = session.run(query)

            # Запрос Type
            query = "MERGE (exploit:EXPLOIT {id: '" + edbid + "'})"
            query = query + "MERGE (type:TYPE {id: '" + typeExploit + "'}) \n"
            query = query + "MERGE (exploit)-[r:EXPLOITtoTYPE]->(type)"
            result = session.run(query)

            #Запрос URL-Exploit
            query = "MERGE (exploit:EXPLOIT {id: '" + edbid + "'})"
            query = query + "MERGE (url:URL {id: '" + linkExploit + "'}) SET url.type='" 'urlExploit' "'"
            query = query + "MERGE (exploit)-[r:EXPLOITtoURL]->(url)"
            result = session.run(query)
            
            #Запрос URL-Code
            query = "MERGE (exploit:EXPLOIT {id: '" + edbid + "'})"
            query = query + "MERGE (url:URL {id: '" + linkCode + "'}) SET url.type='" 'urlCode' "'\n"
            query = query + "MERGE (exploit)-[r:EXPLOITtoURL]->(url)"
            result = session.run(query)

            # Запросы DOMAIN
            if (linkCode.__contains__(domain)):
                query = "MERGE (url:URL {id: '" + linkCode + "'}) \n"
                query = query + "MERGE (dom:DOMAIN {id: '" + domain + "'}) \n"
                query = query + "MERGE (url)-[r:URLtoDOMAIN]->(dom)"
                result = session.run(query)
            
            if (linkExploit.__contains__(domain)):
                query = "MERGE (url:URL {id: '" + linkExploit + "'})"
                query = query + "MERGE (dom:DOMAIN {id: '" + domain + "'}) \n"
                query = query + "MERGE (url)-[r:URLtoDOMAIN]->(dom)"
                result = session.run(query)
            
            print('\033[32m {}'.format(str(exploit_number)))
            exploit_number -= 1
            
    if exploit_number == 25:
        print('\033[31m {}'.format('Too many 404 pages. Please restart application for continue work'))
    else:
        print('\033[32m {}'.format('Work complete'))

if __name__ == '__main__':
    main()
